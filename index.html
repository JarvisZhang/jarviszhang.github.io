
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Jarvis Zhang's Blog</title>
  <meta name="author" content="Jarvis Zhang">

  
  <meta name="description" content="本文主要针对论文“MapReduce: Simplified Data Processing on Large Clusters”进行了概括及总结。 目的 作业输入数据的规模较大
这些任务的运行时间受限，因而需要利用数据中心内的海量节点进行分布式计算
容错及异常处理较复杂且维护成本较高 解决方案 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://JarvisZhang.github.io/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Jarvis Zhang's Blog" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:JarvisZhang.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
    <li><a href="/">
        <span class="blue_light">
            Jarvis Zhang's Blog
        </span>
       
           <span class="blue_dark">
             Step by Step
           </span>
       
    </a></li>
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about">About me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/27/mapreduce/">MapReduce初探</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-03-27T16:25:16+08:00" pubdate data-updated="true">Mar 27<span>th</span>, 2016</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>本文主要针对论文“MapReduce: Simplified Data Processing on Large Clusters”进行了概括及总结。</p>

<h1>目的</h1>

<ul>
<li>作业输入数据的规模较大</li>
<li>这些任务的运行时间受限，因而需要利用数据中心内的海量节点进行分布式计算</li>
<li>容错及异常处理较复杂且维护成本较高</li>
</ul>


<h1>解决方案</h1>

<p>提出了MapReduce架构，将任务的计算流程分为Map和Reduce两个阶段，方法均由用户提供。</p>

<ul>
<li>MAP

<ul>
<li>输入：input pair, e.g. (1, &ldquo;hello world&rdquo;) in Word Count</li>
<li>输出：a set of intermediate key/value pair, e.g. [(&ldquo;hello&rdquo;, [&ldquo;1&rdquo;, &ldquo;2&rdquo;]), (&ldquo;world&rdquo;, [&ldquo;1&rdquo;])] in Word Count</li>
</ul>
</li>
<li>REDUCE

<ul>
<li>输入：an intermediate key + a set of values for this key，如MAP过程的输出</li>
<li>输出：合并上述values，通常最后为zero or one value</li>
</ul>
</li>
<li>案例

<ul>
<li>Distributed Grep, Count of URL Access Frequency</li>
</ul>
</li>
</ul>


<h1>执行流程</h1>

<p><img src="/images/blog/MRWorkflow.png"></p>

<ol>
<li>将输入数据切分为M块，单块大小为16-64MB；

<ul>
<li>128MB，适用于大文件</li>
<li>用户按需求自定义</li>
</ul>
</li>
<li>选取M＋R个状态为idle的worker分配任务；

<ul>
<li>map任务尽量在split块对应节点或其“附近”执行（same network swith）</li>
<li>Master节点维护任务状态信息（idle, in-progress, completed），HTTP通信</li>
<li>若W为用户期望使用的worker数量，一般来说，M通常远大于W，R通常为W的几倍

<ul>
<li>M和R由用户指定，用户根据需求估计，R的数量跟业务相关</li>
<li>W为用户申请的并发资源量</li>
</ul>
</li>
</ul>
</li>
<li>Map Worker读取输入split，对每个pair执行MAP程序；

<ul>
<li>Map读split文件的方式

<ul>
<li>没有对文件实际的切割，只是记录了要处理的数据的位置和长度</li>
<li>map数量与split 数量，splitSize＝max(minSize, Math.min(goalSize, blockSize))

<ul>
<li>minSize，用户指定的最小切分</li>
<li>blockSize，HDFS块大小（128MB）</li>
<li>goalSize＝totalSize／numSplits，numSplits，用户期望的map数量

<ul>
<li>若splitSize大于blockSize，说明需要将多个block合成到一个split，这样有部分block数据需要通过网络读取</li>
<li>若splitSize小于blockSize，说明需要将一个block拆成多个split，增加Map任务数</li>
<li>假设splitSize是默认的64M，现在输入包含3个文件，这3个文件的大小分别为10M，64M，100M，那么这3个文件会被分割为10MB,64MB,64MB,36MB</li>
<li>通常splitSize 就等于blockSize的默认值</li>
</ul>
</li>
<li>一条数据跨split（block），只要不是第一个split，忽略第一条数据</li>
</ul>
</li>
<li>合并小文件，避免block对内存的浪费</li>
</ul>
</li>
<li>提供了默认的读取类型，如&#8221;text&#8221;, &ldquo;key-value pair&#8221;，各类型能够确定数据切分的正确性</li>
<li>用户自定义reader接口，从数据库，内存中读取数据</li>
<li>图中表示实际读取的情况
<img src="/images/blog/HDFSSplit.png"></li>
</ul>
</li>
<li>Map任务将中间结果缓存至内存中，并定期溢写到磁盘（80%）；

<ul>
<li>划分函数（partitioning function）将中间结果分割为R片区域（region）

<ul>
<li>划分函数利用hash，例如{hash(key) mod R}，{hash(Hostname(urlkey)) mod R}</li>
<li>划分数量与Reduce任务数量相同</li>
<li>Region内部的中间结果默认按key增序排列，方便用于随机访问，排序，有时可能说外排序</li>
<li>合并函数（Combiner）在map阶段部分合并key相同的value，本质与Reduce相同，减少网络带宽消耗</li>
</ul>
</li>
<li>缓存结果在磁盘中的位置会被传递至Master节点，后续用于Reduce过程</li>
<li>用户生成的临时辅助文件需要用户自定义保证正确性（原子性，幂等性）

<ul>
<li>map重算，用户处理还是框架处理</li>
</ul>
</li>
</ul>
</li>
<li>Reduce worker从Master处获取文件位置信息，RPC读取map worker中的中间结果

<ul>
<li>所有结果读取后按key进行排序，key值相同的数据被合并</li>
<li>若排序过程中数据量过大需采用外部排序；</li>
</ul>
</li>
<li>Reduce woker逐个处理每个中间结果，对于每个key值及其对应的value set，调用reduce程序

<ul>
<li>Reduce的启动时机，70%</li>
<li>Reduce Task启动过早，长时间占用slot，资源利用率低</li>
<li>Reduce Task启动过晚，Map-Reduce串行执行，拖延任务运行时间</li>
<li>通过已经运行完成的Map Task运行时间估算正在运行的Map Task的剩余运行时间，当Map阶段剩余时间达到一定值后，才开始调度Reduce Task</li>
</ul>
</li>
<li>所有map及reduce任务完成后，master唤醒并返回用户程序，生成R个输出文件</li>
</ol>


<p>上述Map及Reduce的流程可以概括为：</p>

<ul>
<li>Map任务：从GFS读取数据－执行MAP程序－combine过程－输出中间结果至本地磁盘</li>
<li>Reduce任务：从map节点读取中间结果－根据key进行排序－执行REDUCE程序－输出结果至GFS</li>
</ul>


<h1>容错控制</h1>

<ol>
<li>Master节点故障

<ul>
<li>定期checkpoint

<ul>
<li>代价较高</li>
</ul>
</li>
<li>只有单节点在线，Master故障后Client会一直重连</li>
</ul>
</li>
<li>Worker节点故障

<ul>
<li>Master定期ping每个worker，若无响应，则标记为故障节点</li>
<li>故障节点中的map任务需重做状态为运行中（in-progress）及已完成（completed）的，因为中间结果无法读取

<ul>
<li>重做map任务后，所有reduce任务均被通知，数据未读取完成的任务要重新读取</li>
<li>大部分情况下，不要影响Reduce，Reduce重做代价较高</li>
</ul>
</li>
<li>故障节点中的reduce任务只需重做状态为运行中（in-progress）的，已完成的结果已被存值GFS</li>
</ul>
</li>
<li>Straggler

<ul>
<li>当一个MapReduce作业即将完成时，master为剩余状态为in-progress的任务创建多个相同备用任务，任务对应的副本中其中有一个完成即可</li>
<li>预测执行

<ul>
<li>Map和Reduce均有，比例控制</li>
<li>Map和Reduce的输出一致性保存</li>
</ul>
</li>
</ul>
</li>
<li>异常数据记录

<ul>
<li>程序中的bug可能会导致在读取某部分数据时产生异常，阻止作业继续运行</li>
<li>bug不易修复；由第三放库引起；统计分析可忽略</li>
<li>提供直接跳过这部分数据（record）的功能

<ul>
<li>每个worker配有一个信号处理程序（signal handler），捕捉segmentation violations &amp; bus errors，暂存与MapReduce上下文中</li>
<li>若由用户代码生成，signal handler会向master发送特定UDP信息，若master收到多次提醒，则在该任务重新执行时提示其跳过</li>
<li>数据的record与split之间的关系：record指某一条具体数据，具体引起程序崩溃的record位置会被记录，skip bad record</li>
</ul>
</li>
</ul>
</li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/09/16/basic-ways-to-protect-linux-server/">关于Linux服务器安全防护的基本方法</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-09-16T13:38:08+08:00" pubdate data-updated="true">Sep 16<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>楔子</h1>

<p>服务器的安全防护一直以来都是老生长谈的话题，虽然我们平时接触的服务器影响力一般，不会被攻击者处心积虑利用各种漏洞攻击，但做一些基本的防护措施还是很有必要的，可以避免那些常年活跃在互联网上的自动化攻击。</p>

<p>曾有国外安全研究者做过实验，他们搭建了一台蜜罐服务器，该服务上安装了修改后的SSHD版本，记录所有的登陆尝试和存储的所有会话，一旦被黑客攻击，可以查看到所有暴力破解尝试记录，<a href="http://blog.sucuri.net/2013/07/ssh-brute-force-the-10-year-old-attack-that-still-persists.html">实验结果</a>也非常有趣。</p>

<p>SSH暴力破解大约自linux系列产品诞生之后，就衍生出来的一种攻击行为，不仅仅SSH暴力破解，ftp、telnet、smtp、mysql等等都是暴力美学黑客的最爱。</p>

<p>本文总结了一些Linux服务器的基本防护方法，可以有效应对大部分普通网络攻击。实验操作系统版本为CentOS 6</p>

<h1>修改ssh默认端口22</h1>

<p>众所周知，ssh的默认端口为22，这成为了攻击者的首要目标，同时也会引入大量的错误日志。TCP/IP协议中的端口，端口号的范围从0到65535，我们可以指定一个作为ssh登陆端口，注意不要与其它服务冲突。</p>

<p>ssh服务配置文件为/etc/ssh/sshd_config，可以看到端口号指定的配置被注释了，默认为22</p>

<blockquote><p>#Port 22</p></blockquote>

<p>在配置文件中增加一行<code>Port 12345</code>后，重启ssh服务<code>service sshd restart</code>，此时，ssh端口改为了12345，登陆时需要额外指定<code>ssh -p 12345 mytestuser@mytestserver</code>。</p>

<h1>使用Fail2Ban</h1>

<p>fail2ban是一个通过监控日志，防止系统密码被暴力破解的工具，它支持大部分常用服务，如sshd, apache, qmail, proftpd, sasl, asterisk等等，当发现服务器有被暴力破解的迹象时，fail2ban会采取多种手段进行应对，如iptables, tcp-wrapper, shorewall, mail notifications等等。</p>

<h3>安装依赖</h3>

<h5>必选</h5>

<ul>
<li>Python >= 2.4</li>
</ul>


<h5>可选</h5>

<ul>
<li>iptables</li>
<li>shorewall</li>
<li>tcp-wrappers</li>
<li>a working mail command</li>
<li>Gamin the File Alteration Monitor</li>
</ul>


<h3>安装步骤</h3>

<ol>
<li><p>官网下载地址</p>

<p> <a href="http://www.fail2ban.org/wiki/index.php/Downloads">http://www.fail2ban.org/wiki/index.php/Downloads</a></p></li>
<li><p>解压及安装</p>

<pre><code> [root@jsi-dell13 downloads]# tar xzvf 0.8.14.tar.gz
 [root@jsi-dell13 downloads]# cd fail2ban-0.8.14/
 [root@jsi-dell13 fail2ban-0.8.14]# ./setup.py install
 [root@jsi-dell13 fail2ban-0.8.14]# cp files/redhat-initd /etc/init.d/fail2ban
 [root@jsi-dell13 fail2ban-0.8.14]# chmod 755 /etc/init.d/fail2ban 
</code></pre></li>
<li><p>配置开机启动</p>

<pre><code> [root@jsi-dell13 fail2ban-0.8.14]# ln -s /etc/init.d/fail2ban /etc/rc2.d/S20fail2ban
</code></pre></li>
<li><p>配置日志轮询</p>

<p> 创建文件/etc/logrotate.d/fail2ban，写入</p>

<blockquote><p>/var/log/fail2ban.log {</p>

<p>weekly</p>

<p>rotate 7</p>

<p>missingok</p>

<p>compress</p>

<p>postrotate</p>

<p>/usr/bin/fail2ban-client set logtarget /var/log/fail2ban.log >/dev/null</p>

<p>endscript</p>

<p>}</p></blockquote></li>
<li><p>防止ssh字典攻击</p>

<p> 修改配置文件/etc/fail2ban/jail.conf如下</p>

<blockquote><p>[ssh-iptables]</p>

<p>#enabled  = false</p>

<p>enabled  = true</p>

<p>filter   = sshd</p>

<p>action   = iptables[name=SSH, port=ssh, protocol=tcp]</p>

<p>&emsp;&emsp;&emsp;&emsp;sendmail-whois[name=SSH, dest=you@example.com,</p>

<p>&emsp;&emsp;&emsp;&emsp;sender=fail2ban@example.com, sendername=&ldquo;Fail2Ban&rdquo;]</p>

<p>#logpath  = /var/log/sshd.log</p>

<p>logpath  = /var/log/secure</p>

<p>maxretry = 5</p></blockquote>

<p> 以上配置的含义为对于在(findtime)600s内输错5次密码的ip，使用iptables将该ip屏蔽(bandtime)600s。其中findtime和bandtime均可以通过配置修改。详情参见fail2ban<a href="http://www.fail2ban.org/wiki/index.php/MANUAL_0_8">官方手册</a></p></li>
</ol>


<h1>禁止root用户通过ssh方式登陆</h1>

<p>root用户几乎是所有类UNIX系统中都存在的用户，攻击者也常常使用root用户暴力攻击，如果不禁止root远程ssh登陆，攻击者获取密码只是时间问题。</p>

<p>编辑文件/etc/ssh/sshd_config，修改配置选项为<code>PermitRootLogin no</code>，重启ssh服务<code>service sshd restart</code></p>

<p>提示：请确保服务器上还有其它可ssh登录的用户，创建用户步骤如下：</p>

<pre><code>[root@JSI-iDPL02 ~]# useradd jsitest
[root@JSI-iDPL02 ~]# passwd jsitest
</code></pre>

<h1>使用公钥密钥的认证方式</h1>

<p>RSA加密算法是一种非对称加密算法。在公开密钥加密和电子商业中RSA被广泛使用。RSA是1977年由罗纳德·李维斯特（Ron Rivest）、阿迪·萨莫尔（Adi Shamir）和伦纳德·阿德曼（Leonard Adleman）一起提出的。当时他们三人都在麻省理工学院工作。RSA就是他们三人姓氏开头字母拼在一起组成的。</p>

<p>1973年，在英国政府通讯总部工作的数学家克利福德·柯克斯（Clifford Cocks）在一个内部文件中提出了一个相同的算法，但他的发现被列入机密，一直到1997年才被发表。</p>

<p>对极大整数做因数分解的难度决定了RSA算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA算法愈可靠。假如有人找到一种快速因数分解的算法的话，那么用RSA加密的信息的可靠性就肯定会极度下降。但找到这样的算法的可能性是非常小的。今天只有短的RSA钥匙才可能被强力方式解破。到2013年为止，世界上还没有任何可靠的攻击RSA算法的方式。只要其钥匙的长度足够长，用RSA加密的信息实际上是不能被解破的。</p>

<p>具体步骤为：</p>

<ol>
<li><p>生成公钥密钥</p>

<pre><code> [root@JSI-iDPL02 ~]# ssh-keygen -C "jsitest@JSI-iDPL02" -t rsa -b 2048 -f jsitest-JSI-iDPL02
 Generating public/private rsa key pair.
 Enter passphrase (empty for no passphrase): 

 Enter same passphrase again: 

 Your identification has been saved in jsitest-JSI-iDPL02.

 Your public key has been saved in jsitest-JSI-iDPL02.pub.
 The key fingerprint is:
 96:bb:d0:67:11:c8:dc:be:bd:6d:00:7c:59:63:e3:3a jsitest@JSI-iDPL02
 The key's randomart image is:
 +--[ RSA 2048]----+
 |                 |
 |       o o    =  |
 |        +.o  = o |
 |         oo.o .  |
 |        S oo .   |
 |       o . +E    |
 |      . o + .o   |
 |       . +   o.  |
 |        .   ...  |
 +-----------------+
</code></pre>

<p> Enter passphrase的输入为加密所用的字符串，可以视安全强度决定是否置空。</p>

<p> 各参数含义为：</p>

<ul>
<li><p>-C 是对密钥的一个说明，有助于区分不同的密钥用途。</p></li>
<li><p>-t 和 -b 分别指定要生成的密钥类型和密钥长度。</p></li>
<li><p>-f 指定生成的密钥对文件名。公钥文件名为jsitest-JSI-iDPL02.pub，私钥为jsitest-JSI-iDPL02。</p></li>
</ul>


<p> 更多参数请参考ssh-keygen手册</p></li>
<li><p>当前目录下分别生成了公钥jsitest-JSI-iDPL02.pub以及密钥jsitest-JSI-iDPL02，将<strong>密钥拷贝至客户端</strong>备用，将<strong>公钥拷贝至服务器端</strong>备用</p></li>
<li><p>服务器端导入公钥，将对应的公钥加入到服务器上<strong>需要登录的用户</strong>的home目录下的.ssh/authorized_keys文件中</p>

<pre><code> [root@JSI-iDPL02 ~]# cd /home/jsitest/
 [root@JSI-iDPL02 jsitest]# mkdir .ssh
 [root@JSI-iDPL02 ~]# cat jsitest-JSI-iDPL02.pub &gt;&gt; /home/jsitest/.ssh/authorized_keys
</code></pre>

<p> 事实上authorized_keys文件的准确名字是由 sshd_config 中的 AuthorizedKeysFile 配置指定给定的。man sshd_config 获取详细的说明信息。</p>

<p> 注意：authorized_keys文件及其所在的目录以及父目录（一直上溯到该用户的HOME目录为止）的权限必须设置为不能被组和其他人写（可以通过<code>chmod og-w</code>确认），否则其他人只需要修改这个文件即可以以该身份登录到系统上。</p></li>
<li><p>OpenSSH服务端配置</p>

<p> OpenSSH服务器端配置文件一般为/etc/ssh/sshd_config，和公钥认证有关的两个配置项是：</p>

<pre><code> #RSAAuthentication yes
 #PubkeyAuthentication yes
</code></pre>

<p> 其缺省值一般为 yes。如果希望仅打开公钥认证，禁用其他的认证方式，则可以修改下列配置项：</p>

<pre><code> PasswordAuthentication no
 ChallengeResponseAuthentication no  
 UsePAM no
</code></pre>

<p> 重启ssh服务使修改生效</p>

<pre><code> service sshd restart
</code></pre></li>
<li><p>用户登录</p>

<p> 对 OpenSSH 客户端，可以通过<code>ssh -i jsitest-JSI-iDPL02 jsitest@JSI-iDPL</code>快速测试是否工作。</p>

<p> 更一般的方法是将私钥文件jsitest-JSI-iDPL02拷贝至客户端.ssh/目录下，设置.ssh/config配置对不同主机和用户进行配置。如下例：</p>

<pre><code> Host idpl3                                  #别名
     HostName 10.4.9.191                     #完整的域名
     User jsitest                            #登录该域名使用的账号名
     IdentityFile ~/.ssh/jsitest-JSI-iDPL03 #私钥文件的路径
</code></pre>

<p> 这样就可以简化登陆服务器的过程了：</p>

<pre><code> [root@JSI-iDPL03 ~]# ssh idpl2
 Enter passphrase for key '/root/.ssh/jsitest-JSI-iDPL02': 
 Last login: Wed Sep 17 14:38:05 2014 from jsi-idpl03
 [jsitest@JSI-iDPL02 ~]$
</code></pre></li>
</ol>


<h1>禁用ping</h1>

<p>很久以前，一部分操作系统(例如win95)，不能很好处理过大的Ping包，在当时，大部分电脑无法处理大于IPv4最大封包大小（65,535字节）的ping封包。因此发送这样大小的ping可以令目标电脑崩溃。导致出现了Ping to Death的攻击方式(用大Ping包搞垮对方或者塞满网络)，随着操作系统的升级，网络带宽的升级、计算机硬件的升级，大Ping包基本上没有很大的攻击效果(分布式攻击除外)，如果一定要使用Ping包去攻击别的主机，除非是利用TCP/IP协议的其他特性或者网络拓扑结构的缺陷放大攻击的力度(所谓正反馈)，就是俗称的洪水ping攻击。</p>

<p>不过，大部分机构，特别是一些超算中心还是会选择将服务器的ping功能禁掉，以避免不必要的麻烦。</p>

<p>禁用的方法有两种：</p>

<ul>
<li><p>修改文件/proc/sys/net/ipv4/icmp_echo_ignore_all</p>

<p>  不过这种方法只对ipv4有效，ipv6不提供此功能。</p>

<pre><code>  echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all
</code></pre></li>
<li><p>添加iptables规则</p>

<p>  对于ipv4，在/etc/sysconfig/iptables中增加：</p>

<blockquote><p>-A INPUT -j REJECT &mdash;reject-with icmp-host-prohibited</p></blockquote>

<p>  重启iptables</p>

<pre><code>  service iptables restart
</code></pre>

<p>  ipv6的配置文件是/etc/sysconfig/ip6tables，添加规则：</p>

<blockquote><p>-A INPUT -j REJECT &mdash;reject-with icmp6-adm-prohibited</p></blockquote>

<p>  重启ip6tables</p>

<pre><code>  service ip6tables restart
</code></pre></li>
</ul>


<p>至此，服务器不会相应任何ping消息。</p>

<h1>限制用户的su操作</h1>

<p>除了在外部做好防御边界，服务器内部同样需要做好权限管制，当用户需要对服务器进行一些权限较高的维护时，需要通过su切换到root用户，所以为了减少安全隐患，需要限制非管理员的su提权操作。</p>

<p>Linux中有wheel组和staff组的概念，wheel组就类似于管理员的组，只有在这个组中的用户才能进行su操作，否则即使知道root密码，也不能通过su命令切换到root用户。具体步骤为：</p>

<ol>
<li>修改/etc/pam.d/su文件，将<code>auth            required        pam_wheel.so use_uid</code>的注释去掉。</li>
<li>修改/etc/login.defs文件，增加一行<code>SU_WHEEL_ONLY yes</code>配置</li>
<li><p>将新用户jsitest添加到wheel组中</p>

<pre><code> usermod -G wheel jsitest
</code></pre></li>
</ol>


<p>至此，只有在wheel组中的用户才能通过su切换至root用户</p>

<h1>Reference</h1>

<p>[1] 四大Linux服务器攻击方式及防范策略[EB/OL]. <a href="http://www.enet.com.cn/article/2012/0815/A20120815150578.shtml">http://www.enet.com.cn/article/2012/0815/A20120815150578.shtml</a></p>

<p>[2] SSH Brute Force – The 10 Year Old Attack That Still Persists[EB/OL].  Daniel Cid. <a href="http://blog.sucuri.net/2013/07/ssh-brute-force-the-10-year-old-attack-that-still-persists.html">http://blog.sucuri.net/2013/07/ssh-brute-force-the-10-year-old-attack-that-still-persists.html</a></p>

<p>[3] 伪装攻击IP地址的洪水Ping攻击详解[EB/OL]. <a href="http://www.edu.cn/sqt_9968/20110318/t20110318_589483.shtml">http://www.edu.cn/sqt_9968/20110318/t20110318_589483.shtml</a></p>

<p>[4] SSH 公钥认证[EB/OL]. <a href="http://blog.knownsec.com/2012/05/ssh-%E5%85%AC%E9%92%A5%E8%AE%A4%E8%AF%81/">http://blog.knownsec.com/2012/05/ssh-%E5%85%AC%E9%92%A5%E8%AE%A4%E8%AF%81/</a></p>

<p>[5] fail2ban Main Page[EB/OL]. <a href="http://www.fail2ban.org/wiki/index.php/Main_Page">http://www.fail2ban.org/wiki/index.php/Main_Page</a></p>

<p>[6] 使用fail2ban防止暴力破解ssh及vsftpd密码[EB/OL]. <a href="https://www.centos.bz/2012/04/prevent-ssh-break-in-with-fail2ban/">https://www.centos.bz/2012/04/prevent-ssh-break-in-with-fail2ban/</a></p>

<p>[7] RSA加密算法[EB/OL]. <a href="http://zh.wikipedia.org/wiki/RSA%E5%8A%A0%E5%AF%86%E6%BC%94%E7%AE%97%E6%B3%95">http://zh.wikipedia.org/wiki/RSA%E5%8A%A0%E5%AF%86%E6%BC%94%E7%AE%97%E6%B3%95</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/08/23/intel-mic-overview-1/">Intel MIC初探（一）：MIC架构及编程模型概览</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-08-23T19:58:46+08:00" pubdate data-updated="true">Aug 23<span>rd</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>楔子</h1>

<p>Intel MIC（Many Integrated Core）架构是将多个核心整合在一起的处理器，面向HPC（High Performance Computing）领域，旨在引领行业进入百亿亿次计算时代，在其计算机体系中，并非欲取代CPU，而是作为协处理器存在的。MIC芯片通常有数十个精简的x86核心，提供高度并行的计算能力。虽然Intel官方声称原生的CPU程序无需进行大的改动即可在MIC芯片上运行，但是笔者在具体的应用移植过程中发现，真实的应用在MIC架构下通常都会在规模、内存以及第三方库移植等各方面受到一定的制约。</p>

<p>本系列文章将结合实际使用场景对Intel MIC架构及相关技术做简要介绍，并针对两个具有代表性的应用，提出一些启发式的应用移植方法。另外，本文所有的引用文献以及相关参考资料均在文后列出，以资参考。</p>

<h1>硬件架构</h1>

<p>片上对称多处理器（Symmetric Multiprocessor on-a-chip，SMP）是对Intel MIC架构的准确描述方式，Intel Xeon Phi协处理器是基于Intel MIC架构的首款产品。协处理器卡的核心是Intel Xeon Phi协处理器芯片，由61个IA（Intel Architecuture）核组成，这些核执行IA指令集，每个核有4个完全相同的硬件线程。</p>

<p><img class="center" src="/images/blog/IntelMICArchiCore.png" width="250"></p>

<p>关于MIC的缓存组织，每个核的二级缓存组织包括一级数据缓存和指令缓存，大小均为32KB，另外每个核还设计有一个私有的（本地）512KB二级缓存。耳机缓存保持完全的缓存一致性并为片上每个核提供数据。私有的512KB二级缓存总共构成了容量可达30.5MB的片上缓存。所有的二级缓存由全局分布的 (global-distributed) 标签目录保持完全一致.该内存控制器和 PCIe 客户端逻辑分别向协处理器上的 GDDR5 内存和 PCIe 总线提供一种直接接口。所有这些组件都由环形互连连接在一起。被多个核共享的数据将会被复制到需要使用该数据的核所对应的本地二级缓存中，所以，如果每个核都已完美的同步方式共享相同的代码和数据，则有效的二级缓存容量只有512KB。所以，二级缓存的实际可用容量大小与代码和数据在核与线程间的共享情况密切相关。</p>

<p><img class="center" src="/images/blog/Microarchitecture.jpg"></p>

<p>协处理器同时支持4KB（标准）、64KB（非标准）和2MB（超大，标准）页面大小的虚拟内存管理。较小页面的访问会带来总体内存映射空间变小以及最快的访问速度。4KB的页面大小长期以来是Linux的标准设置。64KB的页面大小在现有的微处理器并不常见，同时需要Linux核心的特殊支持。2MB大型存储页支持一般是可用的，但是应用程序或运行环境需要经过一些特殊的修改。在访问大数据集和数组时，使用超大页面能够通过提高TLB命中率提升应用性能，这点在应用优化时需要额外注意。</p>

<p>协处理器芯片的每一个核都包含有一个512位宽的SIMD向量处理单元（VPU），并设计了通信向量化指令集。VPU每个时钟周期可同时处理16个单精度（32bit）或8个双精度（64bit）浮点运算。另外，还包含一个扩展数学单元（EMU，Extended Math Unit）用来实现单精度的超越函数指令集，即通过硬件实现指数、对数、倒数和倒数平方根等常用数学运算。</p>

<p>Intel Xeon Phi协处理器主要针对高度并行化的负载优化，同时支持多种常用的编程语言、编程模式和编程工具。除了大量的处理核心，协处理器还包括提供了并行功能的向量处理器单元。此外，协处理器的PCIe接口、DMA、电源管理、传感器以及散热监控等均有各自的设计特点。</p>

<h1>软件架构</h1>

<p>Intel Xeon Phi协处理器最显著的一个特点是可以启动和运行一个包含网络功能的Linux操作系统，这也是它被成为“协处理器”而非“加速器”（需要依靠主机系统来管理软件应用程序）的主要原因。在协处理器上创建并运行应用程序及系统服务的软件架构包括两个主要部分：</p>

<ul>
<li>开发工具集和运行时环境: Intel C/C++ Fortran编译器，各种函数库。</li>
<li>Intel MPSS(Intel Manycore Platform Software Stack)：中间件接口、通信和控制相关的设备驱动，协处理器管理工具以及协处理器操作系统。</li>
</ul>


<p><img class="center" src="/images/blog/IntelMICSoftwareArchi.png"></p>

<p>MIC的µOS建立的基本执行环境，是其他软件栈的基础。MIC的µOS是基于标准的Linux内核源码。MIC基于Linux的µOS是最小化的，是嵌入式Linux环境通过Linux标准基础（LSB,Linux Standard Base）核心库一直到MIC架构的产物，这也是个未签名的操作系统。µOS提供一些典型的能力，如：进程/任务创建、时序安排、内存管理等。µOS也提供设置、电源和服务器的管理能力。</p>

<p>Intel MPSS提供驱动程序，将PCIe总线映射成一个网络栈中的以太网设备，虚拟化TCP/IP堆栈。系统可以配置桥接TCP/IP网络于所连接的其他网络通信。使用户可以将其作为网络节点直接使用ssh连接到协处理器上。</p>

<p><img class="center" src="/images/blog/IntelMICSoftwareStack.png"></p>

<p>SCIF（Symmetric Communications Interface）实现了协处理器与主处理器之间，协处理器与协处理器之间的通信。它提供了一个统一的对称的API让主处理器和协处理器通过系统中的PCIe总线进行通信，SCIF可以使协处理器通过DMA方式对大数据块进行高速传输，同时可以将主处理器或协处理器的内存空间映射到任意运行在主处理器和协处理器上的进程地址空间中。</p>

<p>MicAccessAPI是的一组C/C++ API，用于监测和配置Intel Xeon Phi协处理器上的各项参数，如电源管理、CPU使用情况、PCI链路情况等。这些API需要依赖scif库（libscif.so）来实现内核软件栈中的通信。</p>

<p><img class="center" src="/images/blog/IntelMICAccessAPIArchi.png"></p>

<h1>编程模型</h1>

<p>MIC拥有较为灵活的编程方式，MIC卡可以作为一个协处理器存在，也可以被看做是一个独立的节点。host端与MIC端的关系可以组合成一下5种关系。</p>

<p><img class="center" src="/images/blog/IntelMICAppMode.png"></p>

<p>而实际中的的应用模式通常不会这样复杂，常用的模式分为Native模式和Offload模式。</p>

<p>Native模式所有负载均在MIC端，通常使用于高并行计算程序，程序直接在MIC执行，这种方式对于应用移植来说难度较小，客观限制较多，如内存，第三方库函数等，提升的性能效果也比较有限，在后续的文章中会对此有所分析。</p>

<p>Offload模式是程序主函数由host发起，对于高度并行的计算部分分载到MIC端，由协处理器完成计算后返回结果。这种方式的优点是可以有更为明显的性能提升效果，缺点是移植较为复杂，特别是对于一些数据结构、算法逻辑较为复杂的代码，甚至需要完全重写。</p>

<h1>Reference</h1>

<p>[1] Jim Jeffers, James Reinders等. <em>Intel Xeon Phi协处理器高性能编程指南</em>[M]. 人民邮电出版社，2014.04</p>

<p>[2] 王恩东, 张清等. <em>MIC高性能计算编程指南</em>[M]. 中国水利水电出版社, 2012.11</p>

<p>[3] George Chrysos. <em>英特尔® 至强融核™ 协处理器（代号 Knights Corner）</em>[EB/OL]. <a href="https://software.intel.com/zh-cn/articles/intel-xeon-phi-coprocessor-codename-knights-corner,">https://software.intel.com/zh-cn/articles/intel-xeon-phi-coprocessor-codename-knights-corner,</a> 2013.01.15</p>

<p>[4] Intel Developer Zone. <em>Intel Xeon Phi systems software developers guide</em>[EB/OL]. <a href="https://software.intel.com/en-us/articles/intel-xeon-phi-coprocessor-system-software-developers-guide,">https://software.intel.com/en-us/articles/intel-xeon-phi-coprocessor-system-software-developers-guide,</a> 2012.11.12</p>

<p>[5] Intel Developer Zone. <em>Intel Xeon Phi coprocessor quick start developers guide</em>[EB/OL]. <a href="https://software.intel.com/en-us/articles/intel-xeon-phi-coprocessor-developers-quick-start-guide,">https://software.intel.com/en-us/articles/intel-xeon-phi-coprocessor-developers-quick-start-guide,</a> 2012.11.12</p>

<p>[6] Intel Developer Zone. <em>An overview of programming for Intel Xeon processors and Intel Xeon Phi coprocessors</em>[EB/OL]. <a href="https://software.intel.com/en-us/articles/an-overview-of-programming-for-intel-xeon-processors-and-intel-xeon-phi-coprocessors,">https://software.intel.com/en-us/articles/an-overview-of-programming-for-intel-xeon-processors-and-intel-xeon-phi-coprocessors,</a> 2012.11.12</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/12/shi-yong-rebasexiu-gai-li-shi-commit/">使用rebase修改历史commit</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-12T22:32:17+08:00" pubdate data-updated="true">May 12<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>最近在使用gerrit做code review，经常遇到的一个情况是需要更改已经commit的代码。</p>

<p>比如对于如下形式的branch tree:</p>

<pre><code>A -- B -- C -- D  (develop)
</code></pre>

<p>问题来了，gerrit上得到了反馈，C上的代码有问题，需要修改。而秉承着“一步一commit“的守则，已经有新的commit提交上去了，目前仓库和远程仓库的HEAD都指向了D。</p>

<p>虽然可以暂时把B merge进去，然后再直接提交一个新commit(E)去修复B上的bug的，但这显然不够优雅，而且把明知道有bug的commit也merge进去本身也是存在风险的，这时，git rebase就派上用场了。</p>

<p>整个主要过程分为四个步骤：</p>

<ol>
<li>修改C中的bug，commit到本地repo为E</li>
<li>输入命令<code>git rebase -i HEAD~3</code></li>
<li>根据提示，调整commit顺序，将最新的commit放到C之后，根据提示将pick改为squash，保存退出。（若存在冲突则处理并git add，继续<code>git rebase --continue</code>）</li>
<li><code>git push --force origin develop</code> # 假设目标分支为develop分支</li>
</ol>


<p>git rebase本来是用来处理分支衍合的，具体原理可以参考官方手册：</p>

<blockquote><p><a href="http://git-scm.com/book/en/Git-Branching-Rebasing">http://git-scm.com/book/en/Git-Branching-Rebasing</a></p></blockquote>

<p>这里我们实际做的是重新调整合并了当前分支的commit顺序，举个例子：</p>

<p>当前分支名为myrebase，文件rebase_test.py与两个commit相关：</p>

<pre><code># commit A
print ('hello rebase')
# commit B
print ('bye')
</code></pre>

<p>现欲在commit A增加为：</p>

<pre><code>print ('May 18th')
</code></pre>

<p>依次做以下操作：</p>

<ul>
<li>修改rabase_test.py</li>
<li><p>新提交一个commit C</p>

<p>  <code>git commit -am "fix on commit A"</code></p></li>
<li><p>使用命令</p>

<p>  <code>git rebase -i HEAD~3</code></p></li>
</ul>


<blockquote><p>-i 表示交互式rebase</p>

<p>HEAD~3 表示对HEAD之前的三次commit进行rebase</p></blockquote>

<p>也可以使用<code>git rebase -i $commit-id-before-commit-A</code></p>

<p>其中$commit-id-before-commit-A为commit A之前commit的id，结果如下：</p>

<blockquote><p>pick 5b55a02 first commit add hello rebase</p>

<p>pick 2f5c48f second commit add bye</p>

<p>pick 225e901 fix on commit A</p>

<p># Rebase 7f8e5eb..225e901 onto 7f8e5eb</p>

<p>#</p>

<p># Commands:</p>

<p>#  p, pick = use commit</p>

<p>#  r, reword = use commit, but edit the commit message</p>

<p>#  e, edit = use commit, but stop for amending</p>

<p>#  s, squash = use commit, but meld into previous commit</p>

<p>#  f, fixup = like &ldquo;squash&rdquo;, but discard this commit&rsquo;s log message</p>

<p>#  x, exec = run command (the rest of the line) using shell</p>

<p>#</p>

<p># These lines can be re-ordered; they are executed from top to bottom.</p>

<p>#</p>

<p># If you remove a line here THAT COMMIT WILL BE LOST.</p>

<p>#</p>

<p># However, if you remove everything, the rebase will > be aborted.</p>

<p>#</p>

<p># Note that empty commits are commented out</p></blockquote>

<ul>
<li>根据注释中对各参数的解释，将前三行改为</li>
</ul>


<blockquote><p>pick 5b55a02 first commit add hello rebase</p>

<p>squash 225e901 fix on commit A</p>

<p>pick 2f5c48f second commit add bye</p></blockquote>

<ul>
<li>若存在冲突，则处理冲突后<code>git commit add .</code>并<code>git rebase --continue</code></li>
<li>由于使用了squash参数，根据提示调整commit信息</li>
<li>看到rebase successful消息后，使用<code>git push --force origin myrebase</code></li>
</ul>


<p>整个过程有可能遇到很多问题，要多利用<code>git diff</code>和 <code>git log</code>来分析</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/21/my-first-blog/">My First Blog</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-21T20:35:33+08:00" pubdate data-updated="true">Apr 21<span>st</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>很久没有写过什么有价值的东西了，当初更新日志的好习惯还是应该保持，不过作为一名技工还是离qq空间之类的东西远一点吧，先用octopress给自己搭一个简单的blog培养一下习惯。</p>

<p>希望能在一年的时间内稍微做出点什么来。</p>

<blockquote><p>Life is short.<br/>
Step by step.<br/>
Stay hungry, stay foolish.</p></blockquote>

<h2>See you</h2>

<pre><code>import time

if __name__ == '__main__':
    time.sleep(365 * 24 * 3600)
</code></pre>
</div>
  
  


    </article>
  
  <div class="pagination">
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/03/27/mapreduce/">MapReduce初探</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/09/16/basic-ways-to-protect-linux-server/">关于Linux服务器安全防护的基本方法</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/08/23/intel-mic-overview-1/">Intel MIC初探（一）：MIC架构及编程模型概览</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/12/shi-yong-rebasexiu-gai-li-shi-commit/">使用rebase修改历史commit</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/21/my-first-blog/">My first Blog</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/jarviszhang">@jarviszhang</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'jarviszhang',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Jarvis Zhang -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'jarviszhang';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
